{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path, csv\n",
    "from pprint import pprint\n",
    "from math import copysign, sqrt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "\n",
    "simulation_names = [name for name in os.listdir(\"gatling-results\") if os.path.isfile(os.path.join(\"gatling-results\", name, \"simulation.log\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing log file for test run primefactorkata-20191108073252673\n",
      "Don't know how to handle REQUEST log ['46', '', '']\n"
     ]
    }
   ],
   "source": [
    "def init_bucket():\n",
    "    return dict(\n",
    "                active_user_count = 0,\n",
    "                count = 0,\n",
    "                mean = 0,\n",
    "                M2 = 0.,\n",
    "                min = float(\"+inf\"),\n",
    "                max = float(\"-inf\"),\n",
    "                median_avg = 0.,\n",
    "                median = 0.,\n",
    "            )\n",
    "\n",
    "def update_bucket(bucket, sample):\n",
    "    #Update extremes\n",
    "    bucket['min'] = min(bucket['min'], sample)\n",
    "    bucket['max'] = max(bucket['max'], sample)\n",
    "\n",
    "    #Update mean/stdev (Welford's Algorithm)\n",
    "    count, mean, M2 = bucket['count'], bucket['mean'], bucket['M2']\n",
    "    count += 1\n",
    "    delta = sample - mean\n",
    "    mean += delta / count\n",
    "    delta2 = sample - mean\n",
    "    M2 += delta * delta2\n",
    "    bucket['M2'] = M2\n",
    "    bucket['count'] = count\n",
    "    bucket['mean'] = mean\n",
    "\n",
    "    #Update median (Jeff McClintock estimate)\n",
    "    bucket['median_avg'] += (sample - bucket['median_avg']) * 0.1\n",
    "    bucket['median'] += copysign( bucket['median_avg'] * 0.01, sample - bucket['median'] );\n",
    "\n",
    "def finalize_bucket(bucket):\n",
    "    count, mean, M2 = bucket['count'], bucket['mean'], bucket['M2']\n",
    "    del bucket['M2']\n",
    "    del bucket['median_avg']\n",
    "    if count > 1:\n",
    "        (mean, variance, sampleVariance) = (mean, M2/count, M2/(count - 1)) \n",
    "        bucket['stdev'] = sqrt(M2/count)\n",
    "    else:\n",
    "        bucket['stdev'] = float(\"nan\")\n",
    "\n",
    "def calculate_stats(name):\n",
    "    print (\"Processing log file for test run {}\".format(name))\n",
    "    user_add_timestamps = set()\n",
    "    time_buckets = {}\n",
    "    total_stats = dict(\n",
    "                total = init_bucket(),\n",
    "                fail = init_bucket(),\n",
    "                success = init_bucket()\n",
    "            )\n",
    "    \n",
    "    def process_user(scenario, userid, action, start_ts, end_ts):\n",
    "        if action != \"START\":\n",
    "            raise RuntimeError(\"Don't know what to do with USER line with action {}\".format(action))\n",
    "        if start_ts != end_ts:\n",
    "            raise RuntimeError(\"Don't know how to handle USER START messages with start/end timestamps {} / {}.\".format(start_ts, end_ts))\n",
    "        user_add_timestamps.add(int(start_ts)//1000)\n",
    "    \n",
    "    def process_request(user, _1, request, start_ts, end_ts, result, _2):\n",
    "        start_ts = float(start_ts)\n",
    "        end_ts = float(end_ts)\n",
    "        dur = end_ts - start_ts\n",
    "        bucket_index = int(end_ts//1000)\n",
    "        success = result == \"OK\"\n",
    "        if bucket_index not in time_buckets:\n",
    "            time_buckets[bucket_index] = dict(\n",
    "                total = init_bucket(),\n",
    "                fail = init_bucket(),\n",
    "                success = init_bucket()\n",
    "            )\n",
    "        #bucket = time_buckets[bucket_index]\n",
    "        update_bucket(total_stats['total'], dur)\n",
    "        update_bucket(time_buckets[bucket_index]['total'], dur)\n",
    "        if success:\n",
    "            update_bucket(time_buckets[bucket_index]['success'], dur)\n",
    "            update_bucket(total_stats['success'], dur)\n",
    "        else:\n",
    "            update_bucket(time_buckets[bucket_index]['fail'], dur)\n",
    "            update_bucket(total_stats['fail'], dur)\n",
    "        \n",
    "    \n",
    "    with open(os.path.join(\"gatling-results\", name, \"simulation.log\")) as inf:\n",
    "        for line in inf:\n",
    "            line = line.rstrip(\"\\n\")\n",
    "            type, *args = line.split(\"\\t\")\n",
    "            if type == \"RUN\":\n",
    "                continue\n",
    "            elif type == \"USER\":\n",
    "                process_user(*args)\n",
    "            elif type == \"REQUEST\":\n",
    "                if len(args) != 7:\n",
    "                    print(\"Don't know how to handle REQUEST log {}\".format(args))\n",
    "                else:\n",
    "                    process_request(*args)\n",
    "            else:\n",
    "                print(type, args)\n",
    "        \n",
    "    for add_ts in sorted(user_add_timestamps):\n",
    "        total_stats['total']['active_user_count'] += 1\n",
    "        total_stats['fail']['active_user_count'] += 1\n",
    "        total_stats['success']['active_user_count'] += 1\n",
    "        for bucket_ts in sorted(time_buckets):\n",
    "            if bucket_ts >= add_ts:\n",
    "                time_buckets[bucket_ts]['total']['active_user_count'] += 1\n",
    "                time_buckets[bucket_ts]['fail']['active_user_count'] += 1\n",
    "                time_buckets[bucket_ts]['success']['active_user_count'] += 1\n",
    "        \n",
    "    finalize_bucket(total_stats['total'])\n",
    "    finalize_bucket(total_stats['fail'])\n",
    "    finalize_bucket(total_stats['success'])\n",
    "    for bucket_ts in sorted(time_buckets):\n",
    "        finalize_bucket(time_buckets[bucket_ts]['total'])\n",
    "        finalize_bucket(time_buckets[bucket_ts]['fail'])\n",
    "        finalize_bucket(time_buckets[bucket_ts]['success'])\n",
    "        \n",
    "    return total_stats, time_buckets\n",
    "        \n",
    "    \n",
    "simulations = {}\n",
    "for name in simulation_names:\n",
    "    stats_total, stats_by_time = calculate_stats(name)\n",
    "    simulations[name] = dict(\n",
    "        stats_total = stats_total,\n",
    "        stats_by_time = stats_by_time,\n",
    "        start_idx = sorted(stats_by_time)[0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace949880b7942b5a236dd87e6103ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='name', options=('primefactorkata-20191108073252673',), value='prim…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def plot_stats_over_time(name = simulation_names, field = simulations[simulation_names[0]]['stats_total']['total'].keys()):\n",
    "    sim = simulations[name]\n",
    "    stats = sim['stats_by_time']\n",
    "\n",
    "    xs = np.arange(len(stats.keys()))\n",
    "    fail_y = np.zeros(len(stats.keys()))\n",
    "    success_y = np.zeros(len(stats.keys())) \n",
    "    total_y = np.zeros(len(stats.keys()))\n",
    "    \n",
    "    for idx, ts in enumerate(sorted(stats)):\n",
    "        fail_y[idx] = stats[ts]['fail'][field]\n",
    "        total_y[idx] = stats[ts]['total'][field]\n",
    "        success_y[idx] = stats[ts]['success'][field]\n",
    "        \n",
    "    plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "    plt.plot(xs, total_y, label=\"Total\")\n",
    "    plt.plot(xs, success_y, label=\"OK\")\n",
    "    plt.plot(xs, fail_y, label=\"Failed\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35206f1c81534e938748a63bf3f56b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='field', options=('active_user_count', 'count', 'mean', 'min', 'max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def plot_comparison(field = simulations[simulation_names[0]]['stats_total']['total'].keys()):\n",
    "    names = []\n",
    "    values = []\n",
    "    for name in simulation_names:\n",
    "        v = simulations[name]['stats_total']['total'][field]\n",
    "        names.append(\"{}\\n{}\".format(name,v))\n",
    "        values.append(v)\n",
    "        \n",
    "\n",
    "    x = np.arange(len(names))\n",
    "    plt.bar(x, values)\n",
    "    plt.xticks(x, names)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
